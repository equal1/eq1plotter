PYGRAM Code documentation
-------------------------

1) Top level PYGRAM 

PYGRAM is a program for plotting and measuring test data. It is primarily intended for
plotting data collected from the Amalfi ATR test system but it is capable of plotting 
data using several other data formats (such as .csv data).

PYGRAM is written using the python computer language, It uses the python 
matplotlib, numpy and xlutils modules.  
 
Python programs can be written which import the pygram module to produce a 
custom plotting script.  The custom PYGRAM script can be very simple which 
just starts the application (e.g. pygram_gui.py), or it can be a complicated 
set of functions which loads multiple logfiles and runs many canned plots 
(e.g. std_spec_plots.py)

The main interactive pygram program used by most users is pygram_gui.py
It provides an interactive window that the user can load logfiles and display
plots. pygram_gui_dev.py is the development version of the interactive program
which typically will have newer features but might not be fully tested.

Other top level scripts:
      spur_matrix.py
      ARGPRD_chiarlo_all.py
      add_meas_data.py
      ARG_8901_Room.py
      std_spec_plots.py

Currently most users are using the pygram_gui_dev.py version of the program.


2) Code Location

The released code for the pygram library module is located in
   N:\sw\release for PC  or  
   /projects/sw/release for linux, 
these are physically the same location on the Netapp file system.
   
All toplevel pygram scripts will import the pygram module (or pygram_dev module 
for the development version). To allow the python to locate the pygram module
the top of the script must contain the following lines:

  #!/usr/local/bin/python
  import sys
  sys.path.append(r'/projects/sw/release')
  sys.path.append(r'N:\sw\release')
  from pygram import *     #or  from pygram_dev import * 
  
Note the first line with #! will allow the script to run python on linux machines,
it may need to be changed depending on the local linux pytho setup.

Python will try to import pygram.py from the current directory first (the directory
where the toplevel script resides), if it does not find it, it will then load it from
the path direcory (N:\sw\release). Therefore you can always run pygram scripts
on a machine by copying the topelevel script and pygram.py onto the PC desktop directory.

Development of pygram is under controlled by Cliosoft SOS design management system.
Work areas for pygram develoment is in
    N:\sw\user\<username>\pygram\src\  or /projects/sw/user/<username>/pygram/src  


3) Pygram Releases

The pygram library module source file is pygram_dev.py, this is checked into SOS
and is available to pygram developers in 
   N:\sw\user\<username>\pygram\src\pygram_dev.py  (for PC users) or 
   /projects/sw/user/<username>/pygram/src/pygram_dev.py (for linux users)
   both directories are the same physical directory on the NETAPP disk filer

The pygram version number is auto assigned by SOS, and will be of the form
'dev1.99' The 'dev' prefix denotes that this is the development version. 

When released the pygram_dev.py is copied to the software release directory
  N:\sw\release (for PC users) or /projects/sw/release (for linux users)
  
When releasing pygram the following copies will be made to the release directory: 
    pygram_dev.py  to    sw/release/pygram_dev.py   X1.99
    pygram_dev.py  to    sw/release/pygram.py       V1.99
    pygram_dev.py  to    sw/release/archive/pygram_dev_1.99.py X1.99 

When pygram is released into the sw/release directory the verision number prefix 
is changed to
   development version  'dev' e.g. dev1.99
   beta release          'X'  e.g.   X1.99
   full release          'V', e.g.   V1.99 
   
The pygram version number is printed out in the output files and on the pygram
window title.

A python script relsw.py is available in the sw/release directory that can be 
used to release the pygram module to the sw/release directory, to run the script
type:

    %> su - projmgr   {password: pass1234 }
    %> cd  /projects/sw/release
    %> relsw.py    /projects/sw/user/<username>/pygram/src/pygram_dev.py   V  
    
 The V parameter is optional, it tells the script to make a V release, 
 if omitted the X release is copied but no V release will be copied.  
 

4) PYGRAM data structures

    self.data = {} is a dictionary variable where all the data is saved (done in add_logfile)
          The dictionary index is the column name of the data, and the value is a list containing  
          all the values in the logfile for that column name, one value for each result line in the logfile.
  
          e.g. Consider a logfile which contains a column with a header name of 'Adj Pwr Out(dBm)'
          and there are a total of 6 test results, these would be saved in the self.data dictionary
          as follows:
              self.data[ 'Adj Pwr Out(dBm)' ] = [ 25.235, 27.654, 29.031, 30.944, 31.552, 33.453 ]

          The 'record_number' refers to the specific value index into the list. rn_start = 0, rn_finish = 5
          Where record_number 0 refers to the first result for the column and has the value 25.235
          and record_number 5 refers to the last value for the column and has the value 33.454
          (typically in the code the variable name used for the first record_number is rn_start, 
          and the last record is rn_finish). When multiple logfiles are loaded the data for 2nd and
          subsequent logfiles is added to the end of the list. 
   
    self.values_dict = {} is a dictioanry where all the unique data values is saved (done in add_logfile)
          The dictionary index is the column name of the data, and the value is a list containing 
          all the unique values for that column, one value for each different value in the logfile.

          e.g. Consider a logfile which contains a column with a header name of 'Vbat(Volt)'
          and there are a total of 6 test results, the first 3 results have the value 3.5 and the last 3
          have the value 4.5 would be saved in the self.data and self_values_dict dictionary
          as follows:
              self.data[ 'Vbat(Volt)' ]        = [ 3.5, 3.5, 3.5, 4.6, 4.6, 4.6 ]
              self.values_dict[ 'Vbat(Volt)' ] = [ 3.5, 4.6 ]

          Not all the column names have an entry in the self_values_dict. Only the common conditions column names
          would be defined.

          Sometimes the self.values_dict can be redefined over a specific record number range. This is
          typically done to provide a list of different values for each seperate logfile. 

    self.values_dict_count = {}  is a dictionary and is closely related to self.values_dict.
           Like self.values_dict the index is is the column name of the data, and the value is a list
           containing the count of each unique value

    self.value_dict_names_original_list   - list of common condition column names 
    self.value_dict_names                 - list f common condition column names
                                               plus rated power columns and any other 
                                               columns selected by the filters




4) PYGRAM Operation

   a) Top level overview 

   When any toplevel pygram script (e.g. pygram_gui_dev.py) is run it first 
   imports the pygram module and then creates an instance of the pygram() object, like:
   
      from pygram_dev import *
      mag = pygram() 

   This will cause pygram.__init__ function to be executed 
   This performs the following actions:
 
   - Initializes the main data dictionary variable self.data where all the results data 
       will be loaded. 
   - Initializes and defines default values for all the widely used pygram variables
   - Runs self.win_init() which causes the main pygram gui window to be dispalyed
   
   The left hand side of the gui has a series of tabs for loading the data, for
   setting the X and Y axes, and for filtering the data. When writing a custom
   pygram script the data log files and the X and Y axes settings can be specified
   in the script this allows the custom script to run without any user input.

   The first operation typically is to load a logfile. Function add_logfile() is run when 
   the gui 'Load Logfile' file is selected. Alteranatively the add_logfile() command
   can be run directly within a custom script. add_logfile can be called multiple times, 
   each time add_logfile() is called it loads a single logfile into the self.data dictionary, 
   each time it appends the results to the self.data dictionary list. 

       mag.add_logfile( filename )

   The add_logfile() function will load the logfile and write the data into the self.data dictionary
   and then run the add_missing_columns() function which will then generate new columns based on the 
   existing column data values. (see details below)

   Once the data is loaded the data can be filtered to only plot data for specific conditions. 

   Next the data can be plotted with the plot_graph_data command. 
plot_graph_data function can be call



   b) Load a logfile mag.add_logfile( filename )

   The add_logfile() function performs these functions 

       - Opens the logfile.
       - Determine the logfile type (e.g atr, excel, or s2p)
       - Go through each line in the logfile
            - Split the line into tab delimited fields
            - Look for a section head (starts with '//')
            - Look for a Test column header (starts with 'T#')        
            - Look for a Parameter data line (starts with '&')
            - Look for a Spurious result line (starts with '//Spurious')
            - Look for a test result data line (starts with a number)
            - Go through each column
                 - Save the columnm value into self.data by appending to the end of the list 
                           self.data[ column ].append( value )
       - Close the logfile

       - If the file is a csv file then run function  self.add_vmux_csvfile which reads in the csv file
       - Run function self.add_missing_columns()   This creates new columns by performing calculations
         on the values in the existing columns, (note it only creates new columns, it does not create new records)

   The add_missing_columns() performs these actions:
       
       - Creates Alert Bit columns from the Alert Register column
       - Creates the Vramp voltage column from the Vramp filename
       - Creates the HBLB column from the Sw Matrix column
       - Creates the Freq(MHz) and Freq(GHz) columns from 'Test Freq(MHz)' column
       - Creates the Sub-band column from the Freq(Mhz) column
       - Creates the s2p mag, phi, dB columns
       - Adds compensation to the s2p data columns
       - Creates Temp(C) colum from the 'Temperature(degree C) column
            (defaults to 25 value to all missing values)
       - Creates the SN field columns from the 'Serial Number' column
       - Creates the Process column from the 'Serial Number' column 
             (defaults to TT)        
       - Runs self.create_values_dict() which goes through all standard parameter 
           column names and generates the self.values_dict[ column ] lists
       - Creates the 'Sw Pwr 400kHz' and 'Sw Pwr 600kHz' columns by taking the 
           worst of +400kHz and -400kHz columns 
       - Create Filtered Spurious columns by taking the Spurious column data and
           applying fixed bandwidth filers and by applying filters defined in the
           spur_freq_threshold_table.csv file.
       - For vramp search tests add 'Adj Pwr Out(dBm)' column from the 'Closest Target Pwr' column
       - Run self.add_vramp2pout_data() which does:
             Goes through all 'Pwr and Eff' tests, recording the 'Adj Pwr Out(dBm)' for every 
                unique set of conditions. 
             Goes through all Non-'Pwr and Eff' tests, looking for conditions which match and writes
                the values from the coresponding 'Pwr and Eff' test into 'Adj Pwr Out(dBm)' column.
       - Run self.calc_amam_pout() which calibrates the PSA AM-AM Distortion Test by looking at the
             'Pwr and Eff' test that immediately preceeds and 'AM-AM Distortion Test' and calculates the
             'AM-Am' to 'Pout(dBm)' scaling factor, and then Creates 'Pout(dBm)' values for all 'AM-AM Distortion'
             tests that follow with the same conditions.
       - Creates 'Pout(dBm)' column from 'Adj Pwr Out(dBm)' or 'PSA Pwr Out(dBm)' columns
       - Creates Pout(W) Pout(V) Poutpk(V) columns from Pout(dBm) column
       - Creates 'AMAM Conversion *' columns
       - Creates 'AMAM Conversion' slope columns using the self.add_slope() function.
       - Creates 'Power Control Slope(dB/V)' column from the Pout(dBm) column using self.add_slope() function
       - Creates 'Gain AM...<emp-limits>' columns
       - For csv files only creates the following columns by scaling or combining exisitn csv column signals
            AVDDRV1* DRV2* DRV3* AVDDPA* VBAT* SCOPE_EFF* VG3* VG2HB* VG2LB* VCP*
            VRAMP SCOPE_CHANNEL_4
       - Run self.add_aclr_data() which creates ACLR5,10,-5,-10 columns by calculating 
               'Pwr at Offset' - 'Pwr at Center' columns
       - Define the  self.product based on the SN column  ( self.values_dict['SN_fld0' ][0] )
       - Creates 'Ref Pout(dBm)' column data and '@ rated_power' columns data.
            If we are doing a VRAMP SEARCH we will get the nominal condtions from the vramp search conditions. 
            If no VRAMP SEARCH data is present then we will get only 4 nominal conditions (one for each sub-band)
            (note at this time we are ignoring vramp search data this is achieved by defining self.vramp_search_testname 
              to a non-existent name)
             - Run self.get_nom_conditions()
             - Foreach nominal conditions found run
                     self.update_nom_conditions()
                     self.add_cal_pout_data( testname='Output Power & Efficiency') 
                         Creates 'Ref Pout(dBm)' column based on 'Pwr & Eff' test results
                     self.add_cal_pout_data( testname='AM-AM AM-PM Distortion')
                         Creates 'Ref Pout(dBm)' based on 'AM-AM Distorion' test results


 5) PYGRAM Reference Power and Rated Power calculations

      The ATR Test system as it is currently configured can perform tests making power measurements
      using a Power Meter and other rf measurements like harmonics and spurs using the PSA.
      Unfortunately only one measurement instrument can be selected for a given test. Many of the performance
      specifications need to be measured at specific output power levels. Therefore for a given measurement
      it is necessary to run two tests. One 'Pwr & Eff' test to establish what the output power is using the
      power meter, and a second test such as 'Spurious' is run under exacly the same conditions using the PSA 
      to measure the rf performance.    

      In order for PYGRAM to make proper measurements against the PRD spec, PYGRAM has to organize the different test 
      results and pair up the the 'Pwr & Eff' test results and the PSA test results that are done under the same
      conditions. 




      How PYGRAM creates 'Pout(dBm)' data:

      When a 'Pwr & Eff' test is run the PA output power is measured on the Power Meter and written into the logfile as 
      an 'Adj Pwr Out(dBm) value. In PYGRAM this value is simply copied to 'Pout(dBm)' column. In addition the 'Pout(dBm)'
      is copied to all other test results which are Not 'Pwr & Eff' tests which are done under exactly the same conditions 
      (i.e. the same vbat, temp, pin, freq, process, vramp etc). 
      (Note: Any PSA tests for which the conditions do not match identically will not have a 'Pout(dBm)' value, and can 
      cause the ARGPRD scripts to fail.)

      Steps to create 'Pout(dBm)', defined in add_missing_columns() and add_vramp2pout_data():

        a) Go through the whole logfile looking for each 'Power & Eff' test, the 'Adj Pwr Out(dBm)' value is then saved 
            against its conditions (Freq, Pin, Vbat, temp etc)
        b) Go through the whole logfile again looking for all Non-'Power & Eff' tests, and if the conditions for the test match
            the conditions from a coresponding 'Powr and Eff' test then write the 'Adj Pwr Out(dBm) value into the Non-'Power and Eff' test.
        c) For all tests if there is a 'Adj Pwr Out(dBm)' value then copy it to 'Pout(dBm)', or else if there is a 'PSA Pwr Out(dBm)
           value then copy it to 'Pout(dBm)'
        d) From Pout(dBm) calculate Pout(V), Pout(W), Poutpk(V) using simple math.



      How PYGRAM determines the Nominal Conditions

        Many tests in the PRD are done under Nominal Conditions. To calculate the 'Ref Pout(dBm)' and '@ Prated' values
        PYGRAM needs to know these Nominal Conditions. 
        Unfortunately the nominal conditions may vary between test script to test script. Therefore PYGRAM has
        to automatically determine which test results in a logfile were done under Nominal Conditions. PYGRAM
        looks at the conditions for each test and looks for values which are closest to PYGRAMs default
        Nominal Condition values. The closest values found in the logfile are then chosen as the Nominal values
        for the tests.

        If more than one part is tested then each test logfile will have different Nominal Conditions. (In fact
        each different Header Section in the logfile will have a different set of Nominal Conditions defined)
        Also a seperate Nominal Frequency is chosen for each of the 4 Sub-Bands.

        The ability of PYGRAM to find the Nominal Conditions is highly dependent on the ATR test script. 
        Sometimes a 'Vramp Search' test is used to define the different Nominal Conditions used. If this
        is the case the user should select 'Use Vramp Search to calc Ref Pout' on the 'Load ARG Script' form.
        This will define multiple Nominal Conditions one for each Vramp Search test. Each Nominal Conditions 
        Section will be bound by the 'Vramp Search' test. 

        Some specifications in the PRD are measured for vbat=2.7v and there maybe 2.7v data in the logfile 
        as well as 3.0v and above data. The 2.7v data requires a seperate Nominal Conditions Section.
        If this is the case the user should select 'Seperate 2.7v data to calc Ref Pout' on the 
        'Load ARG Script' form.
         
        Steps to define Nominal Conditions, defined in add_missing_columns() and get_nominal_conditions():

        a) When PYGRAM starts (when self.__init__ is run) it defines a set of default nominal conditions, these are: 
             self.nom_colname_list = [ 'VSWR','Phase(degree)','Temp(C)','Segments','Vbat(Volt)','Pwr In(dBm)','Regmap']
             self.nom_target_value_list = [ 1,      0,          25     ,   'x',        3.5     ,     3       ,    'x' ]
           When a logfile is read (in self.add_logfile) it looks for test result records which have values which are closest
           to these values.  

          This is done seperately for each of the 4 Sub-band frequency ranges.  The default nominal 
          frequency is defined at the center of each sub-band, and the sub-bands are defined in self.freq_sub_band_list.  

           self.freq_sub_band_list  = [ ['LB-GSM850'    , 820, 850  ],       \
                                        ['LB-EGSM900'   , 880, 915  ],       \
                                        ['HB-DCS1800'   , 1710, 1785],       \
                                        ['HB-PCS1900'   , 1850, 1910],       \
                                        ['LB'           , 800, 950  ],       \
                                        ['HB'           , 1700, 1950],       \
                                      ]
 
        Test which are at Frequencies closest to the center of the band will define the nominal frequency condition, but
        only if there are more than 5 tests at that frequency.



      How PYGRAM creates the 'Ref Pout(dBm)' data:
            
      When a 'Pwr & Eff' test is run under NOMINAL conditions its 'Pout(dBm)' value is saved as a 'Ref Pout(dBm)' value. 
      There will be seperate 'Ref Pout(dBm)' values for each vramp voltage. The 'Ref Pout(dBm)' value is the power output
      from the PA when the PA is running under Nominal conditions (Nominal conditions are center of band frequency, 
      vbat=3.5v, temp=25c, pin=3dBm etc)  For each vramp voltage PYGRAM will copy the 'Ref Pout(dBm)' value to all 
      tests which are run using the same vramp voltage. 
      (Note: Any tests which are run using a vramp voltage for which no Nominal condition 'Pwr & Eff' test was done, 
      will mean 'Ref Pout(dBm) is None for that test, and can cause the ARGPRD scripts to fail, also if PYGRAM fails 
      to correclty identify  the Nominal conditions this can cause the ARGPRD scripts to fail) 

      Steps to create 'Ref Pout(dBm)', defined in add_missing_columns() and add_cal_pout_data():

        a) RefPout is calculated seperately for each logfile and each sub-band and for 2.7v  and 3.0-4.5v sections. (2.7v data is calculated
            seperately from 3.0-4.5v data) So within a given logfile it may have upto 8 sections. (4 sub-bands with 2.7v and 3.5v data)
        b) In the section we identify the 'Power & Eff' tests that are done under Nominal conditions. 
            and save the 'Pout(dBm)' values for each test run with a different vramp voltage. These values will become 
            the 'Ref Pout(dBm)' values used for the rest of the same section. 
        c) Go through the whole section again and write the 'Ref Pout(dBm)' value into each test which matches the same
            vramp voltage.   

        Note: If a test is run using a vramp voltage which does not match any of the vramp voltages used
        in the 'Power & Eff' tests then the 'Ref Pout(dBm) will be None. 
        This may cause problems when running ARGPRD. It is important that all tests which use 'Ref Pout(dBm)' in the PRD
        have 'Power & Eff' tests run with the same vramp voltages. 



      How PYGRAM creates the Rated Power data:

      When 'Ref Pout(dBm)' values have been calculated PYGRAM will mark certain 'Ref Pout(dBm)' as rated powers.
      The rated power levels are defined in ARG script, or can be read implicitly from the PRD.  

      e.g.  in the script there is a definition:
         g.rated_power_values['@ Prated'] = [33.0, 30.0]

      This will define a new column '@ Prated' whose value will be true for all test results which use a vramp voltage
      which gives 33dBm in LB and 30dBm for LB.

      The '@ Prated' value can be used as a filter so that only results which are run using vramps voltages that give 
      the specified rated power value will be plotted.  When creating the '@ Prated' columns PYGRAM will select 
      the closest 'Ref Pout(dBm)' to the specified power level.
      PYGRAM will select different 'vramp voltage' for each sub-band and each section in the logfile.

      Steps to create rated power values, defined in add_missing_columns() and add_cal_pout_data():






4) Code Hierarchy
4a) Loading a Logfile
        
        add_logfile
             add_new_column
             get_filename_from_fullpath
             add_vmux_csvfile
             add_missing_columns
                    hex2bins
                    get_vramp_filename_data
                    get_vramp_filebase
                    create_values_dict
                    add_spurious_data
                          get_spur_freq_from_table
                              get_nearest_val_from_list
                    add_vramp2pout_data
                    calc_amam_pout
                    add_slope
                    scale_time_data
                    add_aclr_data
                    add_values_dict
                    get_nom_conditions
                    add_cal_pout_data   
4b) Filtering Data

4c) Drawing a Graph

         plot_graph_data
             plot_graph_data_core
                  print_columns_list
                  print_values_list
                  select_data
                      add_filter_condtions
                      add_values_dict
                      compare_values
                      create_values_dict
                      get_unique_series_names
                  update_entry_box
                  get_axis_limits
                  get_sub_series
                  get_selected_plot_data
                  get_line_style_indexes
                  remove_bad_data
                  check_nominal_conditions
                  add_all_limits
                  add_spec_limits
                  truncate_name
                  list2str
                  annotate_figure
                  clean_savefilename




4d) Reference Power
4e) Power variation


5) ARGPRD Code Operation

       ARGPRD_charlo_all.py
           open_workbook
           get_prd_data
           get_prd_rated_power_conditions
           copy
           init_xl_tmpfile
           add_all_logfiles_dialog
               add_logfile
           get_audit_str
           print_values_list
           get_test_desc
           gen_graph_table_row
           update_filter_conditions
           set_xyaxes_limits
           set_filter_conditions
           set_spec_limits
           measure_plot_data
           reset_filter_conditions
           
           
6) Important variables
    self.datacount         -  Total number of test measurement lines from all the logfiles
                                  Each line in a logfile with measurement data is converted
                                  into a record.
    self.data[ 'name' ][ 0:self.datacount ]  - Dictionary containing the complete measurement
                              data from the logfiles. Each data column in the logfile becomes
                              a column name in the self.data dictionary. Each column
                              is a list of values whose length is self.datacount. 
                              
    self.values_dict                      - Column Name Dictionary, each entry is a list of
                                              different values in the logfile  
    self.values_dict_count                - Column Name Dictionary, each entry is a list of
                                              value counts for each value in self.values_dict
    self.value_dict_names_original_list   - list of common condition column names 
    self.value_dict_names                 - list f common condition column names
                                               plus rated power columns and any other 
                                               columns selected by the filters
 
    self.filter_conditions 
    self.series_conditions 
                              
    self.logfilenames     - List of the logfilenames read into pygram
    self.csvfilenames     - List of csvfilenames
    self.oplogfilenames   - List of output filenames
    self.savefilename     - Name of saved plotfile 
    self.savedir    -  Directory where output files are to be saved



    